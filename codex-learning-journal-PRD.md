
# Codex Learning Journal – Product Requirements Document (PRD)

## 1. Overview

**Product name:** Codex Learning Journal  
**Version:** v1.0 (training project)  
**Owner:** Human developer (you) working together with OpenAI Codex (CLI, IDE, and Web).  

Codex Learning Journal is a simple web application for tracking small coding exercises, experiments, and learning tasks. It is intentionally small in scope so it can be built end‑to‑end with Codex: from requirements, to implementation, to testing, to deployment.

The app is **single‑user** (no authentication) and stores data in a **local database** (e.g. SQLite) behind a lightweight web API. A simple browser UI lets the user create, view, update, and delete “learning entries”.


## 2. Audience and AI‑specific notes

This PRD is written for both:

- A **human developer** who will make final decisions and run commands.
- **AI coding assistants** (Codex CLI, Codex IDE extension, Codex Web) that will generate and modify code.

When reading this PRD, an AI assistant should:

1. Treat all **“MUST”** statements as hard requirements for v1.  
2. Treat **“SHOULD”** statements as preferred but optional if there is a conflict or time constraint.  
3. Ask for clarification (in natural language) when a requirement is ambiguous.  
4. Prefer **clear, simple, conventional solutions** over clever or novel ones.  
5. Keep the project **small, readable, and easy to understand** for a beginner‑to‑AI developer.


## 3. Goals and Non‑Goals

### 3.1 Product goals (v1)

The product in v1 MUST:

1. Allow the user to record **learning entries** with basic metadata.
2. Persist entries in a **local database** (e.g. SQLite) via a backend API.
3. Provide a minimal but usable **web UI** accessible via a browser.
4. Include a basic **automated test suite** (at least some unit tests).
5. Be suitable as a **training ground** for:
   - Using Codex in the terminal (CLI),
   - Using Codex in an IDE, and
   - Using Codex in the browser (Codex Web / ChatGPT).
6. Be **easy to run locally** with a small number of commands.

### 3.2 Non‑goals (v1)

For v1 the product does **NOT** need to:

- Support multiple users or authentication/authorization.
- Have complex security features (beyond basic framework defaults).
- Provide mobile‑specific layouts or advanced responsive design.
- Support complex search, filtering, or reporting (simple filter/sort is enough).
- Provide integrations with external services (email, calendars, etc.).


## 4. Users and Use Cases

### 4.1 Primary user

- **Role:** Individual developer learning how to use Codex.  
- **Motivation:** Wants a small but realistic project to explore AI‑assisted development, GitHub workflows, and deployment.

### 4.2 Key use cases

1. **Log a new learning task**  
   - User has just done (or plans to do) a small coding exercise.  
   - They open the web app, click “New entry”, fill in the fields, and save.

2. **Review learning history**  
   - User wants to see what they worked on recently.
   - They open the app and see a list of entries, sorted by date.

3. **Update or correct an entry**  
   - User notices a typo or wants to change a status from “Planned” to “Done”.  
   - They edit the entry and save the changes.

4. **Delete an entry**  
   - User wants to remove a test/throwaway entry.  
   - They delete it via the UI and the database is updated accordingly.


## 5. High‑Level Architecture (for AI)

The recommended stack (can be adjusted by the human developer):

- **Frontend:**  
  - A simple React or Next.js UI (TypeScript preferred but not required).  
  - Communicates with the backend via JSON over HTTP.

- **Backend:**  
  - Node.js with Express or Next.js API routes.  
  - Implements REST‑style endpoints for CRUD on learning entries.

- **Database:**  
  - SQLite for simplicity.
  - Accessed via an ORM (e.g. Prisma) or a minimal query layer.

- **Tests:**  
  - Backend tests using Jest or a similar framework.
  - At least one test that hits the “create/read” path.

AI assistants SHOULD keep the project in **one repository** and **one package.json** if possible to reduce complexity.


## 6. Data Model

### 6.1 Entity: LearningEntry

Single main entity for v1:

| Field           | Type        | Required | Notes                                                     |
|----------------|-------------|----------|-----------------------------------------------------------|
| id             | integer/uuid| YES      | Primary key. Autogenerated by the database.              |
| title          | string      | YES      | Short summary of the learning task (max ~100 chars).     |
| description    | string      | NO       | Free‑text notes (markdown plain text is fine).           |
| status         | enum        | YES      | One of: `PLANNED`, `IN_PROGRESS`, `DONE`.                |
| difficulty     | enum        | NO       | One of: `EASY`, `MEDIUM`, `HARD`.                        |
| tags           | string[]    | NO       | Stored as a simple string array or comma‑separated list. |
| createdAt      | datetime    | YES      | Timestamp when entry created.                            |
| updatedAt      | datetime    | YES      | Timestamp when entry last updated.                       |

AI assistants SHOULD implement enums in a way that is natural for the chosen language/framework.


## 7. Functional Requirements

### 7.1 Create entry

- **FR‑1:** User MUST be able to create a new `LearningEntry` from the UI.
- **FR‑2:** The following fields MUST be available in the create form:
  - title (mandatory),
  - description (optional),
  - status (default `PLANNED`),
  - difficulty (optional),
  - tags (optional, simple comma‑separated string is acceptable).
- **FR‑3:** On successful creation:
  - The entry is inserted into the database.
  - The user is returned to the list view and sees the new entry.

### 7.2 Read/list entries

- **FR‑4:** The main page MUST show a list of existing entries.
- **FR‑5:** Entries MUST be sorted by `createdAt` descending (newest first).
- **FR‑6:** Each list item MUST at least show `title`, `status`, and `createdAt`.

Optional but recommended:

- **FR‑7 (SHOULD):** Provide a simple filter/sort control (e.g. filter by status).

### 7.3 Update entry

- **FR‑8:** User MUST be able to open an existing entry in an edit form.
- **FR‑9:** User MUST be able to change any editable field and save.
- **FR‑10:** Changes MUST be persisted to the database and reflected in the UI.

### 7.4 Delete entry

- **FR‑11:** User MUST be able to delete an entry from the list or detail view.
- **FR‑12:** App SHOULD ask for confirmation before deletion.
- **FR‑13:** On deletion, the entry MUST be removed from the database and list.


## 8. Non‑Functional Requirements

### 8.1 Performance

- The app is local and small; no strict performance targets.  
- Pages SHOULD load in under 1 second on a typical laptop dev environment.

### 8.2 Reliability

- The app SHOULD start consistently with a small set of commands (`npm install`, `npm run dev` or similar).  
- If the database file is missing, the app SHOULD be able to initialize/migrate it automatically (or provide a clear CLI command for that).

### 8.3 Usability

- The UI MUST be usable in a desktop browser with a mouse/keyboard.  
- Basic accessibility practices SHOULD be followed (proper labels, semantic HTML).

### 8.4 Security

- No authentication in v1.
- AI assistants SHOULD avoid obvious security anti‑patterns (e.g. SQL injection).  
- Database access MUST go through a controlled layer (ORM or parameterised queries).


## 9. API Requirements

The backend MUST expose a minimal JSON API for `LearningEntry`:

- `GET /api/entries` – Return list of all entries.  
- `GET /api/entries/:id` – Return a single entry by id.  
- `POST /api/entries` – Create a new entry.  
- `PUT /api/entries/:id` – Update an existing entry.  
- `DELETE /api/entries/:id` – Delete an entry.

AI assistants SHOULD:

- Validate input (at least sanity checks on required fields).  
- Use appropriate HTTP status codes (201 on create, 400 on bad request, 404 if not found, etc.).


## 10. Testing and Acceptance Criteria

### 10.1 Automated tests

For v1, minimally:

- At least **one test** that creates an entry via the API and then reads it back.
- At least **one test** that validates input (e.g. rejects a missing `title`).

Tests SHOULD be runnable via a single command, e.g.:

- `npm test` or `npm run test`

### 10.2 Manual acceptance tests

The project is **acceptable** for v1 when:

1. Developer can clone the repo, run install commands, start the app, and open it in a browser.  
2. The full CRUD flow works manually:
   - Create a new entry,
   - See it in the list,
   - Edit it,
   - Delete it.
3. Basic tests pass locally.
4. The app can be deployed using a standard Node/React hosting platform (e.g. Vercel/Render/Netlify) with minimal configuration.


## 11. Git and Configuration Requirements

- The project MUST be tracked in a Git repository hosted on GitHub.
- The default branch SHOULD be `main`.
- The repository MUST include at minimum:
  - `README.md` with setup instructions.
  - This PRD (`codex-learning-journal-PRD.md` or similar).
  - A simple `CONTRIBUTING.md` explaining how to run tests and propose changes.
- AI assistants SHOULD:
  - Work on feature branches when making larger changes.
  - Avoid committing directly to `main` unless explicitly instructed.


## 12. Future Enhancements (Out‑of‑Scope for v1)

These features are explicitly out of scope for v1 but MAY be considered as stretch goals:

- User accounts and authentication (e.g. sign‑in with GitHub).  
- Advanced analytics (charts of time spent, completion rate, etc.).  
- Export to CSV/Markdown.  
- Tag‑based dashboards.  
- Multi‑language support for the UI.  


## 13. Prompting Guidelines for AI Assistants

When the human developer asks you (Codex) to work on this project, you SHOULD:

1. Start from this PRD and restate your understanding of the current task.  
2. Ask clarifying questions if the requested change conflicts with this PRD.  
3. Use small, iterative changes rather than large refactors by default.  
4. Clearly list files you plan to modify before making changes.  
5. After changes:
   - Summarize what you did,
   - Show relevant diffs where appropriate,
   - Propose next steps or tests to run.

If the human asks you to **ignore or override** part of this PRD, obey the human but clearly state which requirement you are deviating from, so they can update this document if needed.
